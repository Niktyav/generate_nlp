# Домашнее задание 2. Разработка чат-бота на основе генеративной модели.

Необходимо разработать чат-бот, используя генеративный подход. Бот должен вести диалог как определенный персонаж сериала, имитируя стиль и манеру конкретного персонажа сериала. Важно учесть особенности речи и темы, которые поднимает персонаж, его типичные реакции.


# Описание проекта

Данный проект представляет генеративного чат-бота, имитирующего манеру речи Чендлера Бинга – одного из главных персонажей ситкома «Друзья». Цель проекта – создать диалоговую модель, способную отвечать пользователю с фирменным сарказмом и юмором Чендлера. Это решает задачу стилизации ответов под конкретного персонажа, что может использоваться для развлекательных чат-ботов или творческих приложений. В основе бота лежит предобученная языковая модель (Llama 1B), дообученная на репликах Чендлера из сценария сериала. Модель была дообучена методами fine-tuning на специальном датасете диалогов, чтобы научиться генерировать ответы в стиле Чендлера.

# Данные

Основой для обучения послужили два источника данных:  
  - Сценарии сериала «Друзья» – датасет с репликами персонажей сериала за 10 сезонов (Kaggle: Friends TV Scripts)​
    https://www.kaggle.com/datasets/amandam1/friends-scripts  Из него извлекались диалоговые пары вопрос–ответ, где ответом была реплика Чендлера Бинга, а вопросом – предыдущая реплика другого персонажа (контекст разговора). Каждая такая пара представляет мини-диалог: на фразу собеседника модель должна выдать ответ в стиле Чендлера.
  - Сценарии фильмов (IMSDB) – подборка скриптов различных фильмов с IMSDB​ https://imsdb.com/all-scripts.html Они использовались для формирования нерелевантных примеров и негативных классов при обучении вспомогательной модели-классификатора. Эти данные помогают убедиться, что бот отличает “чужой” стиль от речи Чендлера.
    
Предобработка данных:  Для сценариев «Друзей» данные преобразованы в структуру с колонками: character (имя говорящего персонажа), q (реплика-вопрос/контекст) и a (реплика-ответ). Отфильтрованы диалоги так, чтобы ответ a принадлежал Чендлеру. В итоге получилось около 8 189 пар реплик, из которых ~90% пошло на обучение (7370 примеров) и 10% на тестирование (819 примеров).  Для датасета IMSDB были случайным образом выбраны реплики, не относящиеся к Чендлеру, для обучения классификатора стиля.


# Обучение модели

Модель для чат-бота была обучена методом тонкой настройки (fine-tuning) на собранных репликах Чендлера. В качестве исходной использована компактная языковая модель Llama 3.2 – 1B Instruct от проекта Unsloth (около 1 млрд параметров, оригинальная LLAMA 3.2 от запрещенной организации недоступна). Чтобы эффективно дообучить такую большую модель на доступной GPU, применялись техники сжатия и адаптации:
    -Квантование 4-bit (QLoRA): базовая модель загружалась в 4-битном формате с помощью bitsandbytes для снижения требуемой памяти.  
    - Parameter-Efficient Fine-Tuning: использовалась библиотека PEFT (метод LoRA) для обучения только небольшого числа дополнительных параметров. Конфигурация LoRA: размер внутреннего представления r=16, коэффициент α=32, dropout=0.05 – такие параметры позволяют обучить адаптацию, не изменяя исходные весы модели.
    - Гиперпараметры обучения: одна эпоха по всему обучающему набору (эпох больше не использовали во избежание переобучения). Размер батча – 1 (эффективный батч 2 за счет gradient_accumulation_steps=2), алгоритм оптимизации AdamW (режим 32-bit оптимизатора для 4-bit весов), шаг обучения learning rate = 2e-4, стратегия warmup_steps=10. Обучение проводилось в смешанной точности (BF16) на GPU. Логирование велось каждые 50–100 шагов, оценка на валидационной выборке – каждые 50 шагов.

В ходе обучения наблюдалось устойчивое снижение функции потерь как на тренировочных, так и на тестовых данных. На графике ниже показана динамика training loss и validation loss в процессе обучения модели:

Рис. 1: График обучения модели – изменение функции потерь на обучающей (оранжевая линия) и проверочной (красная линия) выборках по мере тренировки.

После одной эпохи финальное значение ошибки на валидации составило ~2.72, снизившись с ~3.17 в начале обучения. Обучение заняло около ~40 минут на GPU (Mobile RTX 4090). Дообученная модель сохранена под именем “llama-3.1-8b-chat-chandler” (а также экспортирована в gguf-формат LLaMA.CPP, для запуска в продуктовой среде).

# Структура репозитория

hw1/   
├── data/    
│ ├── other/ # сценарии фильмов    
│ └── friends.csv  # датасет реплик друзей   
├── models/ # Сохранённые модели ( llama-3.1-8b-chat-chandler и cдоступны по [ссылке](https://disk.yandex.ru/d/WigCN0l2PrsCGg)   
├── chatbot/   
│ ├── requirements.txt # Зависимости проекта   
│ ├── dockerfile # Конфигурация контейнера Flask  
│ └── app.py # Flask приложение для веб-сервиса   
├── img/ # Графики и иллюстрации   
│ ├── gradio.jpg # Пример диалога  
│ ├── llama_cpp.jpg # пример диалога   
│ ├── biencoder_learning.jpg # График сходимости Bi-Encoder   
│ └── crossencoder_learning.jpg# График сходимости Cross-Encoder    
├── docker-compose.yml # Файл для контейнеризации (Flask, Llama.cpp и т.д.)    
├── friends_generate.ipynb # Ноутбук с кодом предобработки данных, обучением моделей и инференсом в gradio   
└── README.md # Отчёт (данный файл)   

# Инференс

Качество ответов чат-бота проверялось до и после обучения модели на специальных примерах. Ниже приведены сравнения ответов до обучения (исходная модель) и после fine-tuning (дообученная на репликах Чендлера). Видно, что изначально модель не умеет должным образом реагировать на фразы, а после обучения начинает отвечать более осмысленно и в характерной манере:

    Пользователь: “C’mon, you’re going out with the guy! There’s gotta be something wrong with him!”
    Модель до обучения: Эхо-вопроса. (Модель просто повторяет: “c’mon, you’re going out with the guy…”, добавляя служебные токены)
    Модель после обучения: Отрицает с возмущением. “No, I’m not going out with him! I’m just going out with the guy! He’s not the guy!”

    Пользователь: “Okay, everybody relax. This is not even a date. It’s just two people going out to dinner and– not having sex.”
    Модель до обучения: Неуверенный ответ. “okay, everybody relax. this is not even a date. it’s just two people going out to dinner and– not...” (не завершает фразу)
    Модель после обучения: Извиняется, запинаясь. “I know, I know, I’m sorry. But I’m really, really, really, really, really, really…” (начинает оправдываться, пусть и несколько повторяясь)

    Пользователь: “Oh, yeah. Had that dream.”
    Модель до обучения: Бессвязный выход. “oh, yeah. had that dream.<|...|>[PTM]<|...|>[French]…” (модель выдала фрагменты служебных токенов, пытаясь переключить язык)
    Модель после обучения: Уточняет с интересом. “Oh, yeah? What happened? What happened? What happened? …” (модель реагирует вопросом, хотя и повторяет его излишне)

Как видно из примеров, до обучения модель либо повторяла входные фразы, либо генерировала бессмысленные токены. После fine-tuning ответы стали содержать осмысленные реплики, близкие по стилю к Чендлеру (саркастичные отрицания, уточнения и т.д.). Несмотря на некоторую повторяемость или недосказанность, прогресс очевиден – бот начал поддерживать диалог, а не просто перефразировать вопросы.

Для количественной оценки была обучена отдельная модель-классификатор, распознающая, принадлежит ли данная фраза Чендлеру или нет (на основе тех же данных Friends vs. IMSDB). Она показала, что ~99% ответов дообученного бота классифицируются как реплики Чендлера, тогда как у исходной модели только ~52% выходов напоминали стиль Чендлера. Это свидетельствует о значительном улучшении качества и стилеобразования ответов.

# Запуск локального веб-сервиса(gradio)

После обучения модель была интегрирована в простой веб-интерфейс с помощью Gradio. Это позволяет общаться с чат-ботом через браузер и в ноутбуке. 


# Выводы

В результате проделанной работы удалось обучить компактного чат-бота, воспроизводящего речи персонажа Чендлера Бинга. Дообученная модель заметно превосходит исходную в умении поддерживать диалог и выдавать саркастичные, соответствующие персонажу ответы. Классификатор стиля подтвердил, что практически все генерируемые ботом реплики совпадают со стилем Чендлера. Тем не менее, качество всё ещё ограничено размером модели:
Ограничения: Модель ~1B параметров иногда повторяет слова или сбивается, ёмкость её памяти ограничена, из-за чего юмористические ответы могут быть простыми. В некоторых случаях ответы не точно совпадают с оригинальными репликами Чендлера, а передают лишь общее настроение.
Возможные улучшения:    
  - Для более убедительного результата стоит использовать более крупную модель (например, 7B или 13B параметров) 
  - Можно увеличить объем тренировочных данных (например, добавить больше контекста диалога, учитывать 2-3 предыдущие реплики).
  - Применение методов RLHF (обучение с подкреплением от обратной связи человека) для усиления сходства с персонажем и устранения повторов. 

В целом, проект показал, что даже относительно небольшая языковая модель при правильном дообучении способна перенять речевые особенности конкретного персонажа. Бот Чендлер демонстрирует базовый уровень сарказма и характерных фраз, и при дальнейшей доработке может стать ещё более похожим на оригинал.
